本文列举了关于深度强化学习（Deep Reinforcement Learning，DRL）的一些论文，同时欢迎大家提交自己阅读过的论文。

目录
•    值函数相关的文章

•    策略相关的文章

•    离散控制相关的文章

•    连续控制相关的文章

•    文本处理领域相关的文章

•    计算机视觉领域相关的文章

•    机器人领域相关的文章

•    游戏领域相关的文章

•    蒙特卡洛树搜索相关的文章

•    逆强化学习相关的文章

•    搜索优化相关的文章

•    多任务和迁移学习相关的文章

•    多智能体相关的文章

•    层次化学习相关的文章

### 值函数相关的文章

Model-Free Episodic Control, C. Blundell et al., arXiv, 2016.  <br>
Safe and Efficient Off-Policy Reinforcement Learning, R. Munos et al., arXiv, 2016.<br>
Deep Successor Reinforcement Learning, T. D. Kulkarni et al., arXiv, 2016.<br>
Unifying Count-Based Exploration and Intrinsic Motivation, M. G. Bellemare et al., arXiv, 2016.<br>
Control of Memory, Active Perception, and Action in Minecraft, J. Oh et al., ICML, 2016.<br>
Dynamic Frame skip Deep Q Network, A. S. Lakshminarayanan et al., IJCAI Deep RL Workshop, 2016.<br>
Hierarchical Reinforcement Learning using Spatio-Temporal Abstractions and Deep Neural Networks, R. Krishnamurthy et al., arXiv, 2016.<br>
Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation, T. D. Kulkarni et al., arXiv, 2016.<br>
Continuous Deep Q-Learning with Model-based Acceleration, S. Gu et al., ICML, 2016.<br>
Deep Exploration via Bootstrapped DQN, I. Osband et al., arXiv, 2016.<br>
Value Iteration Networks, A. Tamar et al., arXiv, 2016.<br>
Learning to Communicate to Solve Riddles with Deep Distributed Recurrent Q-Networks, J. N. Foerster et al., arXiv, 2016.<br>
Asynchronous Methods for Deep Reinforcement Learning, V. Mnih et al., arXiv, 2016.<br>
Mastering the game of Go with deep neural networks and tree search, D. Silver et al., Nature, 2016.<br>
Increasing the Action Gap: New Operators for Reinforcement Learning, M. G. Bellemare et al., AAAI, 2016.<br>
How to Discount Deep Reinforcement Learning: Towards New Dynamic Strategies, V. François-Lavet et al., NIPS Workshop, 2015.<br>
Multiagent Cooperation and Competition with Deep Reinforcement Learning, A. Tampuu et al., arXiv, 2015.<br>
Strategic Dialogue Management via Deep Reinforcement Learning, H. Cuayáhuitl et al., NIPS Workshop, 2015.<br>
Learning Simple Algorithms from Examples, W. Zaremba et al., arXiv, 2015.<br><br>
Dueling Network Architectures for Deep Reinforcement Learning, Z. Wang et al., arXiv, 2015.<br>
Prioritized Experience Replay, T. Schaul et al., ICLR, 2016.<br>
Deep Reinforcement Learning with an Action Space Defined by Natural Language, J. He et al., arXiv, 2015.<br>
Deep Reinforcement Learning in Parameterized Action Space, M. Hausknecht et al., ICLR, 2016.<br><br>
Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control, F. Zhang et al., arXiv, 2015.<br>
Generating Text with Deep Reinforcement Learning, H. Guo, arXiv, 2015.<br>
Deep Reinforcement Learning with Double Q-learning, H. van Hasselt et al., arXiv, 2015.<br>
Recurrent Reinforcement Learning: A Hybrid Approach, X. Li et al., arXiv, 2015.<br>
Continuous control with deep reinforcement learning, T. P. Lillicrap et al., ICLR, 2016.<br>
Language Understanding for Text-based Games Using Deep Reinforcement Learning, K. Narasimhan et al., EMNLP, 2015.<br>
Action-Conditional Video Prediction using Deep Networks in Atari Games, J. Oh et al., NIPS, 2015.<br>
Deep Recurrent Q-Learning for Partially Observable MDPs, M. Hausknecht and P. Stone, arXiv, 2015.<br>
Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models, B. C. Stadie et al., arXiv, 2015.<br>
Massively Parallel Methods for Deep Reinforcement Learning, A. Nair et al., ICML Workshop, 2015.<br>
Human-level control through deep reinforcement learning, V. Mnih et al., Nature, 2015.<br>
Playing Atari with Deep Reinforcement Learning, V. Mnih et al., NIPS Workshop, 2013.<br>


### 策略相关的文章

Curiosity-driven Exploration in Deep Reinforcement Learning via Bayesian Neural Networks, R. Houthooft et al., arXiv, 2016.<br>
Benchmarking Deep Reinforcement Learning for Continuous Control, Y. Duan et al., ICML, 2016.<br>
Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection, S. Levine et al., arXiv, 2016.<br>
Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization, C. Finn et al., arXiv, 2016.<br>
Asynchronous Methods for Deep Reinforcement Learning, V. Mnih et al., arXiv, 2016.<br>
Mastering the game of Go with deep neural networks and tree search, D. Silver et al., Nature, 2016.<br>
Memory-based control with recurrent neural networks, N. Heess et al., NIPS Workshop, 2015.<br>
MazeBase: A Sandbox for Learning from Games, S. Sukhbaatar et al., arXiv, 2016.<br>
ADAAPT: A Deep Architecture for Adaptive Policy Transfer from Multiple Sources, J. Rajendran et al., arXiv, 2015.<br>
Continuous control with deep reinforcement learning, T. P. Lillicrap et al., ICLR, 2016.<br>
Learning Continuous Control Policies by Stochastic Value Gradients, N. Heess et al., NIPS, 2015.<br>
High-Dimensional Continuous Control Using Generalized Advantage Estimation, J. Schulman et al., ICLR, 2016.<br>
End-to-End Training of Deep Visuomotor Policies, S. Levine et al., arXiv, 2015.<br>
Deterministic Policy Gradient Algorithms, D. Silver et al., ICML, 2015.<br>
Trust Region Policy Optimization, J. Schulman et al., ICML, 2015.<br>


### 离散控制相关的文章

Model-Free Episodic Control, C. Blundell et al., arXiv, 2016.<br>
Safe and Efficient Off-Policy Reinforcement Learning, R. Munos et al., arXiv, 2016.<br>
Deep Successor Reinforcement Learning, T. D. Kulkarni et al., arXiv, 2016.<br>
Unifying Count-Based Exploration and Intrinsic Motivation, M. G. Bellemare et al., arXiv, 2016.<br>
Control of Memory, Active Perception, and Action in Minecraft, J. Oh et al., ICML, 2016.<br>
Dynamic Frame skip Deep Q Network, A. S. Lakshminarayanan et al., IJCAI Deep RL Workshop, 2016.<br>
Hierarchical Reinforcement Learning using Spatio-Temporal Abstractions and Deep Neural Networks, R. Krishnamurthy et al., arXiv, 2016.<br>
Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation, T. D. Kulkarni et al.,<br> arXiv, 2016.
Deep Exploration via Bootstrapped DQN, I. Osband et al., arXiv, 2016.<br>
Value Iteration Networks, A. Tamar et al., arXiv, 2016.<br>
Learning to Communicate to Solve Riddles with Deep Distributed Recurrent Q-Networks, J. N. Foerster et al., arXiv, 2016.<br>
Asynchronous Methods for Deep Reinforcement Learning, V. Mnih et al., arXiv, 2016.<br>
Mastering the game of Go with deep neural networks and tree search, D. Silver et al., Nature, 2016.<br>
Increasing the Action Gap: New Operators for Reinforcement Learning, M. G. Bellemare et al., AAAI, 2016.<br>
How to Discount Deep Reinforcement Learning: Towards New Dynamic Strategies, V. François-Lavet et al., NIPS Workshop, 2015.<br>
Multiagent Cooperation and Competition with Deep Reinforcement Learning, A. Tampuu et al., arXiv, 2015.<br>
Strategic Dialogue Management via Deep Reinforcement Learning, H. Cuayáhuitl et al., NIPS Workshop, 2015.<br>
Learning Simple Algorithms from Examples, W. Zaremba et al., arXiv, 2015.<br>
Dueling Network Architectures for Deep Reinforcement Learning, Z. Wang et al., arXiv, 2015.<br>
Better Computer Go Player with Neural Network and Long-term Prediction, Y. Tian et al., ICLR, 2016.<br>
Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning, E. Parisotto, et al., ICLR, 2016.<br>
Policy Distillation, A. A. Rusu et at., ICLR, 2016.<br>
Prioritized Experience Replay, T. Schaul et al., ICLR, 2016.<br>
Deep Reinforcement Learning with an Action Space Defined by Natural Language, J. He et al., arXiv, 2015.<br>
Deep Reinforcement Learning in Parameterized Action Space, M. Hausknecht et al., ICLR, 2016.<br>
Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control, F. Zhang et al., arXiv, 2015.<br>
Generating Text with Deep Reinforcement Learning, H. Guo, arXiv, 2015.<br>
ADAAPT: A Deep Architecture for Adaptive Policy Transfer from Multiple Sources, J. Rajendran et al., arXiv, 2015.<br>
Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning, S. Mohamed and D. J. Rezende, arXiv, 2015.<br>
Deep Reinforcement Learning with Double Q-learning, H. van Hasselt et al., arXiv, 2015.<br>
Recurrent Reinforcement Learning: A Hybrid Approach, X. Li et al., arXiv, 2015.<br>
Language Understanding for Text-based Games Using Deep Reinforcement Learning, K. Narasimhan et al., EMNLP, 2015.<br>
Giraffe: Using Deep Reinforcement Learning to Play Chess, M. Lai, arXiv, 2015.<br>
Action-Conditional Video Prediction using Deep Networks in Atari Games, J. Oh et al., NIPS, 2015.<br>
Deep Recurrent Q-Learning for Partially Observable MDPs, M. Hausknecht and P. Stone, arXiv, 2015.<br>
Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences, H. Mei et al., arXiv, 2015.<br>
Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models, B. C. Stadie et al., arXiv, 2015.<br>
Universal Value Function Approximators, T. Schaul et al., ICML, 2015.<br>
Massively Parallel Methods for Deep Reinforcement Learning, A. Nair et al., ICML Workshop, 2015.<br>
Human-level control through deep reinforcement learning, V. Mnih et al., Nature, 2015.<br>
Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning, X. Guo et al., NIPS, 2014.<br>
Playing Atari with Deep Reinforcement Learning, V. Mnih et al., NIPS Workshop, 2013.<br>

### 连续控制相关的文章

Curiosity-driven Exploration in Deep Reinforcement Learning via Bayesian Neural Networks, R. Houthooft et al., arXiv, 2016.<br>
Benchmarking Deep Reinforcement Learning for Continuous Control, Y. Duan et al., ICML, 2016.<br>
Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection, S. Levine et al., arXiv, 2016.<br>
Continuous Deep Q-Learning with Model-based Acceleration, S. Gu et al., ICML, 2016.<br>
Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization, C. Finn et al., arXiv, 2016.<br>
Asynchronous Methods for Deep Reinforcement Learning, V. Mnih et al., arXiv, 2016.<br>
Memory-based control with recurrent neural networks, N. Heess et al., NIPS Workshop, 2015.<br>
Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning, S. Mohamed and D. J. Rezende, arXiv, 2015.<br>
Continuous control with deep reinforcement learning, T. P. Lillicrap et al., ICLR, 2016.<br>
Learning Continuous Control Policies by Stochastic Value Gradients, N. Heess et al., NIPS, 2015.<br>
Learning Deep Neural Network Policies with Continuous Memory States, M. Zhang et al., arXiv, 2015.<br>
High-Dimensional Continuous Control Using Generalized Advantage Estimation, J. Schulman et al., ICLR, 2016.<br>
End-to-End Training of Deep Visuomotor Policies, S. Levine et al., arXiv, 2015.<br>
DeepMPC: Learning Deep Latent Features for Model Predictive Control, I. Lenz, et al., RSS, 2015.<br>
Deterministic Policy Gradient Algorithms, D. Silver et al., ICML, 2015.<br>
Trust Region Policy Optimization, J. Schulman et al., ICML, 2015.<br>

### 文本处理领域相关的文章

Strategic Dialogue Management via Deep Reinforcement Learning, H. Cuayáhuitl et al., NIPS Workshop, 2015.<br>
MazeBase: A Sandbox for Learning from Games, S. Sukhbaatar et al., arXiv, 2016.<br>
Deep Reinforcement Learning with an Action Space Defined by Natural Language, J. He et al., arXiv, 2015.<br>
Generating Text with Deep Reinforcement Learning, H. Guo, arXiv, 2015.<br>
Language Understanding for Text-based Games Using Deep Reinforcement Learning, K. Narasimhan et al., EMNLP, 2015.<br>
Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences, H. Mei et al., arXiv, 2015.<br>

### 计算机视觉领域相关的文章

Model-Free Episodic Control, C. Blundell et al., arXiv, 2016.<br>
Deep Successor Reinforcement Learning, T. D. Kulkarni et al., arXiv, 2016.<br>
Unifying Count-Based Exploration and Intrinsic Motivation, M. G. Bellemare et al., arXiv, 2016.<br>
Control of Memory, Active Perception, and Action in Minecraft, J. Oh et al., ICML, 2016.<br>
Dynamic Frame skip Deep Q Network, A. S. Lakshminarayanan et al., IJCAI Deep RL Workshop, 2016.<br>
Hierarchical Reinforcement Learning using Spatio-Temporal Abstractions and Deep Neural Networks, R. Krishnamurthy et al., arXiv, 2016.<br>
Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation, T. D. Kulkarni et al., arXiv, 2016.<br>
Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection, S. Levine et al., arXiv, 2016.<br>
Deep Exploration via Bootstrapped DQN, I. Osband et al., arXiv, 2016.<br>
Value Iteration Networks, A. Tamar et al., arXiv, 2016.<br>
Asynchronous Methods for Deep Reinforcement Learning, V. Mnih et al., arXiv, 2016.<br>
Mastering the game of Go with deep neural networks and tree search, D. Silver et al., Nature, 2016.<br>
Increasing the Action Gap: New Operators for Reinforcement Learning, M. G. Bellemare et al., AAAI, 2016.<br>
Memory-based control with recurrent neural networks, N. Heess et al., NIPS Workshop, 2015.<br>
How to Discount Deep Reinforcement Learning: Towards New Dynamic Strategies, V. François-Lavet et al., NIPS Workshop, 2015.<br>
Multiagent Cooperation and Competition with Deep Reinforcement Learning, A. Tampuu et al., arXiv, 2015.<br>
Dueling Network Architectures for Deep Reinforcement Learning, Z. Wang et al., arXiv, 2015.<br>
Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning, E. Parisotto, et al., ICLR, 2016.<br>
Better Computer Go Player with Neural Network and Long-term Prediction, Y. Tian et al., ICLR, 2016.<br>
Policy Distillation, A. A. Rusu et at., ICLR, 2016.<br>
Prioritized Experience Replay, T. Schaul et al., ICLR, 2016.<br>
Deep Reinforcement Learning in Parameterized Action Space, M. Hausknecht et al., ICLR, 2016.<br>
Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control, F. Zhang et al., arXiv, 2015.<br>
Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning, S. Mohamed and D. J. Rezende, arXiv, 2015.<br>
Deep Reinforcement Learning with Double Q-learning, H. van Hasselt et al., arXiv, 2015.<br>
Continuous control with deep reinforcement learning, T. P. Lillicrap et al., ICLR, 2016.<br>
Giraffe: Using Deep Reinforcement Learning to Play Chess, M. Lai, arXiv, 2015.<br>
Action-Conditional Video Prediction using Deep Networks in Atari Games, J. Oh et al., NIPS, 2015.<br>
Learning Continuous Control Policies by Stochastic Value Gradients, N. Heess et al., NIPS, 2015.<br>
Deep Recurrent Q-Learning for Partially Observable MDPs, M. Hausknecht and P. Stone, arXiv, 2015.<br>
Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models, B. C. Stadie et al., arXiv, 2015.<br>
High-Dimensional Continuous Control Using Generalized Advantage Estimation, J. Schulman et al., ICLR, 2016.<br>
End-to-End Training of Deep Visuomotor Policies, S. Levine et al., arXiv, 2015.<br>
Universal Value Function Approximators, T. Schaul et al., ICML, 2015.<br>
Massively Parallel Methods for Deep Reinforcement Learning, A. Nair et al., ICML Workshop, 2015.<br>
Trust Region Policy Optimization, J. Schulman et al., ICML, 2015.<br>
Human-level control through deep reinforcement learning, V. Mnih et al., Nature, 2015.<br>
Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning, X. Guo et al., NIPS, 2014.<br>
Playing Atari with Deep Reinforcement Learning, V. Mnih et al., NIPS Workshop, 2013.<br>

### 机器人领域相关的文章

Curiosity-driven Exploration in Deep Reinforcement Learning via Bayesian Neural Networks, R. Houthooft et al., arXiv, 2016.<br>
Benchmarking Deep Reinforcement Learning for Continuous Control, Y. Duan et al., ICML, 2016.<br>
Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection, S. Levine et al., arXiv, 2016.<br>
Continuous Deep Q-Learning with Model-based Acceleration, S. Gu et al., ICML, 2016.<br>
Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization, C. Finn et al., arXiv, 2016.<br>
Asynchronous Methods for Deep Reinforcement Learning, V. Mnih et al., arXiv, 2016.<br>
Memory-based control with recurrent neural networks, N. Heess et al., NIPS Workshop, 2015.<br>
Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control, F. Zhang et al., arXiv, 2015.<br>
Learning Continuous Control Policies by Stochastic Value Gradients, N. Heess et al., NIPS, 2015.<br>
Learning Deep Neural Network Policies with Continuous Memory States, M. Zhang et al., arXiv, 2015.<br>
High-Dimensional Continuous Control Using Generalized Advantage Estimation, J. Schulman et al., ICLR, 2016.<br>
End-to-End Training of Deep Visuomotor Policies, S. Levine et al., arXiv, 2015.<br>
DeepMPC: Learning Deep Latent Features for Model Predictive Control, I. Lenz, et al., RSS, 2015.<br>
Trust Region Policy Optimization, J. Schulman et al., ICML, 2015.<br>

### 游戏领域相关的文章

Model-Free Episodic Control, C. Blundell et al., arXiv, 2016.<br>
Safe and Efficient Off-Policy Reinforcement Learning, R. Munos et al., arXiv, 2016.<br>
Deep Successor Reinforcement Learning, T. D. Kulkarni et al., arXiv, 2016.<br>
Unifying Count-Based Exploration and Intrinsic Motivation, M. G. Bellemare et al., arXiv, 2016.<br>
Control of Memory, Active Perception, and Action in Minecraft, J. Oh et al., ICML, 2016.<br>
Dynamic Frame skip Deep Q Network, A. S. Lakshminarayanan et al., IJCAI Deep RL Workshop, 2016.<br>
Hierarchical Reinforcement Learning using Spatio-Temporal Abstractions and Deep Neural Networks, R. Krishnamurthy et al., arXiv, 2016.<br>
Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation, T. D. Kulkarni et al., arXiv, 2016.<br>
Deep Exploration via Bootstrapped DQN, I. Osband et al., arXiv, 2016.<br>
Learning to Communicate to Solve Riddles with Deep Distributed Recurrent Q-Networks, J. N. Foerster et al., arXiv, 2016.<br>
Asynchronous Methods for Deep Reinforcement Learning, V. Mnih et al., arXiv, 2016.<br>
Mastering the game of Go with deep neural networks and tree search, D. Silver et al., Nature, 2016.<br>
Increasing the Action Gap: New Operators for Reinforcement Learning, M. G. Bellemare et al., AAAI, 2016.<br>
How to Discount Deep Reinforcement Learning: Towards New Dynamic Strategies, V. François-Lavet et al., NIPS Workshop, 2015.<br>
Multiagent Cooperation and Competition with Deep Reinforcement Learning, A. Tampuu et al., arXiv, 2015.<br>
MazeBase: A Sandbox for Learning from Games, S. Sukhbaatar et al., arXiv, 2016.<br>
Dueling Network Architectures for Deep Reinforcement Learning, Z. Wang et al., arXiv, 2015.<br>
Better Computer Go Player with Neural Network and Long-term Prediction, Y. Tian et al., ICLR, 2016.<br>
Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning, E. Parisotto, et al., ICLR, 2016.<br>
Policy Distillation, A. A. Rusu et at., ICLR, 2016.<br>
Prioritized Experience Replay, T. Schaul et al., ICLR, 2016.<br>
Deep Reinforcement Learning with an Action Space Defined by Natural Language, J. He et al., arXiv, 2015.<br>
Deep Reinforcement Learning in Parameterized Action Space, M. Hausknecht et al., ICLR, 2016.<br>
Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning, S. Mohamed and D. J. Rezende, arXiv, 2015.<br>
Deep Reinforcement Learning with Double Q-learning, H. van Hasselt et al., arXiv, 2015.<br>
Continuous control with deep reinforcement learning, T. P. Lillicrap et al., ICLR, 2016.<br>
Language Understanding for Text-based Games Using Deep Reinforcement Learning, K. Narasimhan et al., EMNLP, 2015.<br>
Giraffe: Using Deep Reinforcement Learning to Play Chess, M. Lai, arXiv, 2015.<br>
Action-Conditional Video Prediction using Deep Networks in Atari Games, J. Oh et al., NIPS, 2015.<br>
Deep Recurrent Q-Learning for Partially Observable MDPs, M. Hausknecht and P. Stone, arXiv, 2015.<br>
Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models, B. C. Stadie et al., arXiv, 2015.<br>
Universal Value Function Approximators, T. Schaul et al., ICML, 2015.<br>
Massively Parallel Methods for Deep Reinforcement Learning, A. Nair et al., ICML Workshop, 2015.<br>
Trust Region Policy Optimization, J. Schulman et al., ICML, 2015.<br>
Human-level control through deep reinforcement learning, V. Mnih et al., Nature, 2015.<br>
Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning, X. Guo et al., NIPS, 2014.<br>
Playing Atari with Deep Reinforcement Learning, V. Mnih et al., NIPS Workshop, 2013.<br>


### 蒙特卡洛树搜索相关的文章

Mastering the game of Go with deep neural networks and tree search, D. Silver et al., Nature, 2016.<br>
Better Computer Go Player with Neural Network and Long-term Prediction, Y. Tian et al., ICLR, 2016.<br>
Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning, X. Guo et al., NIPS, 2014.<br>


### 逆强化学习相关的文章

Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization, C. Finn et al., arXiv, 2016.<br>
Maximum Entropy Deep Inverse Reinforcement Learning, M. Wulfmeier et al., arXiv, 2015.<br>


### 多任务和迁移学习相关的文章

Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning, E. Parisotto, et al., ICLR, 2016.<br>
Policy Distillation, A. A. Rusu et at., ICLR, 2016.<br>
ADAAPT: A Deep Architecture for Adaptive Policy Transfer from Multiple Sources, J. Rajendran et al., arXiv, 2015.<br>
Universal Value Function Approximators, T. Schaul et al., ICML, 2015.<br>

### 搜索优化相关的文章
Unifying Count-Based Exploration and Intrinsic Motivation, M. G. Bellemare et al., arXiv, 2016.<br>
Curiosity-driven Exploration in Deep Reinforcement Learning via Bayesian Neural Networks, R. Houthooft et al., arXiv, 2016.<br>
Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation, T. D. Kulkarni et al., arXiv, 2016.<br>
Deep Exploration via Bootstrapped DQN, I. Osband et al., arXiv, 2016.<br>
Action-Conditional Video Prediction using Deep Networks in Atari Games, J. Oh et al., NIPS, 2015.<br>
Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models, B. C. Stadie et al., arXiv, 2015.<br>

### 多智能体相关的文章

Learning to Communicate to Solve Riddles with Deep Distributed Recurrent Q-Networks, J. N. Foerster et al., arXiv, 2016.<br>
Multiagent Cooperation and Competition with Deep Reinforcement Learning, A. Tampuu et al., arXiv, 2015.<br>


### 层次化学习相关的文章

Deep Successor Reinforcement Learning, T. D. Kulkarni et al., arXiv, 2016.<br>
Hierarchical Reinforcement Learning using Spatio-Temporal Abstractions and Deep Neural Networks, R. Krishnamurthy et al., arXiv, 2016.<br>
Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation, T. D. Kulkarni et al., arXiv, 2016.<br>


特别致谢
本部分内容参考[链接](https://github.com/junhyukoh/deep-reinforcement-learning-papers)
