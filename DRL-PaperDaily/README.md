### Deep Reinforcement Learning Paper Daily


> This document used to display the latest papers about Deep Reinforcement Learning, 

### Continuous updating......

Issue# 15：2020-2-20
----
1. [Locally Private Distributed Reinforcement Learning](https://arxiv.org/abs/2001.11718) by Hajime Ono, Tsubasa Takahashi
2. [Effective Diversity in Population-Based Reinforcement Learning](https://arxiv.org/abs/2002.00632) by Jack Parker-Holder, Stephen Roberts
3. [Deep Reinforcement Learning for Autonomous Driving: A Survey](https://arxiv.org/abs/2002.00444) by B Ravi Kiran, Patrick Pérez
4. [Attractive or Faithful? Popularity-Reinforced Learning for Inspired Headline Generation](https://arxiv.org/abs/2002.02095) by Yun-Zhu Song, AAAI 2020
5. [Asymptotically Efficient Off-Policy Evaluation for Tabular Reinforcement Learning](https://arxiv.org/abs/2001.10742) by Ming Yin, Yu-Xiang Wang (Includes appendix. Accepted for AISTATS 2020)


Issue# 14：2020-2-10
----
1. [Model-based Multi-Agent Reinforcement Learning with Cooperative Prioritized Sweeping](https://arxiv.org/abs/2001.07527) by Eugenio Bargiacchi, Ann Nowé
2. [Reinforcement Learning with Probabilistically Complete Exploration](https://arxiv.org/abs/2001.06940) by Philippe Morere, Fabio Ramos
3. [Algorithms in Multi-Agent Systems: A Holistic Perspective from Reinforcement Learning and Game Theory](https://arxiv.org/abs/2001.06487) by Yunlong Lu, Kai Yan
4. [Local Policy Optimization for Trajectory-Centric Reinforcement Learning](https://arxiv.org/abs/2001.08092) by Patrik Kolaric, Daniel Nikovski
5. [On Simple Reactive Neural Networks for Behaviour-Based Reinforcement Learning](https://arxiv.org/abs/2001.07973) by Ameya Pore, Gerardo Aragon-Camarasa
6. [Graph Constrained Reinforcement Learning for Natural Language Action Spaces](https://arxiv.org/abs/2001.08837) by Prithviraj Ammanabrolu, Matthew Hausknecht(Accepted to ICLR 2020)
7. [Challenges and Countermeasures for Adversarial Attacks on Deep Reinforcement Learning](https://arxiv.org/abs/2001.09684) by Inaam Ilahi, Dusit Niyato
8. [Active Task-Inference-Guided Deep Inverse Reinforcement Learning](https://arxiv.org/abs/2001.09227) by Farzan Memarian, Ufuk Topcu


Issue# 13：2020-1-20
----
1. [Direct and indirect reinforcement learning](https://arxiv.org/abs/1912.10600) by  Yang Guan, Bo Cheng
2. [Parameterized Indexed Value Function for Efficient Exploration in Reinforcement Learning](https://arxiv.org/abs/1912.10577) by  Tian Tan, Vikranth R. Dwaracherla
3. [Continuous-Discrete Reinforcement Learning for Hybrid Control in Robotics](https://arxiv.org/abs/2001.00449) by Michael Neunert, Martin Riedmiller, Presented at the 3rd Conference on Robot Learning (CoRL 2019)
4. [Meta Reinforcement Learning with Autonomous Inference of Subtask Dependencies](https://arxiv.org/abs/2001.00248) by Sungryull Sohn, Honglak Lee, ICLR2020
5. [Long-Term Visitation Value for Deep Exploration in Sparse Reward Reinforcement Learning](https://arxiv.org/abs/2001.00119) by Simone Parisi, Joni Pajarinen
6. [Optimal Options for Multi-Task Reinforcement Learning Under Time Constraints](https://arxiv.org/abs/2001.01620) by  Manuel Del Verme, Gianluca Baldassarre
7. [MushroomRL: Simplifying Reinforcement Learning Research](https://arxiv.org/abs/2001.01102) by Carlo D'Eramo, Jan Peters

Issue# 12：2020-1-10
----

1. [Predictive Coding for Boosting Deep Reinforcement Learning with Sparse Rewards](https://arxiv.org/abs/1912.13414) by Xingyu Lu, Pieter Abbeel 
2. Interestingness Elements for Explainable Reinforcement Learning: Understanding Agents' Capabilities and Limitations](https://arxiv.org/abs/1912.09007) byPedro Sequeira, Melinda Gervasio
3. [Reward-Conditioned Policies](https://arxiv.org/abs/1912.13465) by Aviral Kumar, Sergey Levine 
4. [Pseudo Random Number Generation: a Reinforcement Learning approach](https://arxiv.org/abs/1912.11531) by Luca Pasqualini, Maurizio Parton
5. [Distributed Reinforcement Learning for Decentralized Linear Quadratic Control: A Derivative-Free Policy Optimization Approach](https://arxiv.org/abs/1912.09135) by Yingying Li, Na Li
6. [Deep Reinforcement Learning for Motion Planning of Mobile Robots](https://arxiv.org/abs/1912.09260) by Leonid Butyrev, Christopher Mutschler

Issue# 11：2019-12-19
----
later updating......

Issue# 10：2019-12-13
----
1. [On-policy Reinforcement Learning with Entropy Regularization](https://arxiv.org/abs/1912.01557) by Jingbin Liu, Shuai Liu
2. [Human-Robot Collaboration via Deep Reinforcement Learning of Real-World Interactions](https://arxiv.org/abs/1912.01715) by Jonas Tjomsland, A. Aldo Faisal,  **NeurIPS'19** Workshop on Robot Learning: Control and Interaction in the Real World
3. [Iterative Policy-Space Expansion in Reinforcement Learning](https://arxiv.org/abs/1912.02532) by Jan Malte Lichtenberg, Özgür Şimşek, **NeurIPS 2019**
4. [Deep Model Compression via Deep Reinforcement Learning](https://arxiv.org/abs/1912.02254) by Huixin Zhan, Yongcan Cao
5. [Observational Overfitting in Reinforcement Learning](https://arxiv.org/abs/1912.02975) by Xingyou Song, Behnam Neyshabur
6. [Reinforcement Learning Upside Down: Don't Predict Rewards -- Just Map Them to Actions](https://arxiv.org/abs/1912.02875) by Juergen Schmidhuber
7. [Learning Sparse Representations Incrementally in Deep Reinforcement Learning](https://arxiv.org/abs/1912.04002) by  Fernando Hernandez-Garcia, **Richard S. Sutton**
89. [Entropy Regularization with Discounted Future State Distribution in Policy Gradient Methods](https://arxiv.org/abs/1912.05104) by Riashat Islam, Doina Precup, **NeurIPS2019** Optimization Foundations of Reinforcement Learning Workshop



Issue# 9：2019-12-3
----
1. [Learning Representations in Reinforcement Learning:An Information Bottleneck Approach](https://arxiv.org/abs/1911.05695) by Pei Yingjun, Hou Xinwen
2. [Learning to Communicate in Multi-Agent Reinforcement Learning : A Review()](https://arxiv.org/abs/1911.05438) by  Mohamed Salah Zaïem, Etienne Bennequin
3. [Accelerating Training in Pommerman with Imitation and Reinforcement Learning](https://arxiv.org/abs/1911.04947) by  Hardik Meisheri, Harshad Khadilkar, Presented at Deep Reinforcement Learning workshop, NeurIPS-2019(★★)



Issue# 8：2019-11-18
----
1. [Real-Time Reinforcement Learning](https://arxiv.org/abs/1911.04448) by Simon Ramstedt, Christopher Pal
2. [Provably Convergent Off-Policy Actor-Critic with Function Approximation](https://arxiv.org/abs/1911.04384) by Shangtong Zhang, Shimon Whiteson, Optimization Foundations of Reinforcement Learning Workshop at NeurIPS 2019
3. [Driving Reinforcement Learning with Models](https://arxiv.org/abs/1911.04400) by  Pietro Ferraro, Giovanni Russo
4. [Non-Cooperative Inverse Reinforcement Learning](https://arxiv.org/abs/1911.04220) by  Xiangyuan Zhang, Tamer Başar
5. [Learning to reinforcement learn for Neural Architecture Search](https://arxiv.org/abs/1911.03769) by  J. Gomez Robles, J. Vanschoren



Issue# 7：2019-11-15
----
1. [Fully Bayesian Recurrent Neural Networks for Safe Reinforcement Learning](https://arxiv.org/abs/1911.03308) by Matt Benatan, Edward O. Pyzer-Knapp
2. [Model-free Reinforcement Learning with Robust Stability Guarantee](https://arxiv.org/abs/1911.02875) by Minghao Han, Wei Pan, NeurIPS 2019 Workshop on Robot Learning: Control and Interaction in the Real World, Vancouver, Canada
3. [Option Compatible Reward Inverse Reinforcement Learning](https://arxiv.org/abs/1911.02723) by  Rakhoon Hwang, Hyung Ju Hwang
4. [Deep Reinforcement Learning for Distributed Uncoordinated Cognitive Radios Resource Allocation](https://arxiv.org/abs/1911.03366) by Ankita Tondwalkar, Andres Kwasinski,  submitted in the IEEE ICC 2020 Conference
5. [Experienced Deep Reinforcement Learning with Generative Adversarial Networks (GANs) for Model-Free Ultra Reliable Low Latency Communication](https://arxiv.org/abs/1911.03264) by  Ali Taleb Zadeh Kasgari, H. Vincent Poor
6. [Mapless Navigation among Dynamics with Social-safety-awareness: a reinforcement learning approach from 2D laser scans](https://arxiv.org/abs/1911.03074) by Jun Jin, Martin Jagersand


Issue# 6：2019-11-8
----
1. [Gym-Ignition: Reproducible Robotic Simulations for Reinforcement Learning](https://arxiv.org/abs/1911.01715) by Diego Ferigo, Daniele Pucci, Accepted in SII2020
2. [DeepRacer: Educational Autonomous Racing Platform for Experimentation with Sim2Real Reinforcement Learning](https://arxiv.org/abs/1911.01562) by Bharathan Balaji, Dhanasekar Karuppasamy


Issue# 5：2019-11-7
----
1. [Online Robustness Training for Deep Reinforcement Learning](https://arxiv.org/pdf/1911.00887.pdf) by Marc Fischer, Martin Vechev, 2019-11-3
2. [Maximum Entropy Diverse Exploration: Disentangling Maximum Entropy Reinforcement Learning](https://arxiv.org/pdf/1911.00828.pdf) by Andrew Cohen, Xiangrong Tong, 2019-11
3. [Gradient-based Adaptive Markov Chain Monte Carlo](https://arxiv.org/pdf/1911.01373.pdf) by Michalis K. Titsias, Petros Dellaportas, NeurIPS 2019
4. [Keeping Your Distance: Solving Sparse Reward Tasks Using Self-Balancing Shaped Rewards](https://arxiv.org/pdf/1911.01417.pdf) by Alexander Trott, Richard Socher, NeurIPS 2019
5. [Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit Structure in MDPs](https://arxiv.org/pdf/1911.00954.pdf) by Andrea Zanette, Emma Brunskill


Issue# 4：2019-11-5
----
1. [Cascaded LSTMs based Deep Reinforcement Learning for Goal-driven Dialogue](https://arxiv.org/abs/1910.14229) by Yue Ma, Hong Chen, NLPCC 2017
2. [Dynamic Cloth Manipulation with Deep Reinforcement Learning](https://arxiv.org/abs/1910.14475) by Rishabh Jangir, Carme Torras, ICRA'2020
3. [Meta-Learning to Cluster](https://arxiv.org/abs/1910.14134) by Yibo Jiang, Nakul Verma


Issue# 3：2019-11-4
----
1. [Robust Model-free Reinforcement Learning with Multi-objective Bayesian Optimization](https://arxiv.org/abs/1910.13399) by Matteo Turchetta, Sebastian Trimpe, ICRA2020
2. [Certified Adversarial Robustness for Deep Reinforcement Learning](https://arxiv.org/abs/1910.12908) by Björn Lütjens, Jonathan P, CORL2019
3. [Generalization of Reinforcement Learners with Working and Episodic Memory](https://arxiv.org/abs/1910.13406) by Meire Fortunato, Charles Blundell, NeurIPS 2019
4. [Constrained Reinforcement Learning Has Zero Duality Gap](https://arxiv.org/abs/1910.13393) by Santiago Paternain, Alejandro Ribeiro
5. [Feedback Linearization for Unknown Systems via Reinforcement Learning](https://arxiv.org/abs/1910.13272) by Tyler Westenbroek, Claire J. Tomlin
6.  [Multiplayer AlphaZero](https://arxiv.org/abs/1910.13012) by Nick Petosa, Tucker Balch




Issue# 2：2019-11-3
----
1. [Learning Fairness in Multi-Agent Systems](https://arxiv.org/abs/1910.14472) by Jiechuan Jiang, Zongqing Lu, NeurIPS2019
2. [VASE: Variational Assorted Surprise Exploration for Reinforcement Learning](https://arxiv.org/abs/1910.14351) by Haitao Xu, Lech Szymanski.
3. [RLINK: Deep Reinforcement Learning for User Identity Linkage](https://arxiv.org/abs/1910.14273) by Xiaoxue Li, Jianlong Tan



Issue# 1：2019-11-2
----
1. [Distributed Model-Free Algorithm for Multi-hop Ride-sharing using Deep Reinforcement Learning](https://arxiv.org/abs/1910.14002) by Ashutosh Singh, Abubakr Alabbasi, and Vaneet Aggarwal, 2019-10-30
2. [DADI: Dynamic Discovery of Fair Information with Adversarial Reinforcement Learning](https://arxiv.org/abs/1910.13983) by Michiel A. Bakker, Duy Patrick Tu,2019-10-30
3. [Robust Distributed Accelerated Stochastic Gradient Methods for Multi-Agent Networks](https://arxiv.org/abs/1910.08701) by Alireza Falla, 2019-10-30
4. [Automatic Testing and Falsification with Dynamically Constrained Reinforcement Learning](https://arxiv.org/abs/1910.13645) by Xin Qin, Nikos Aréchiga, Andrew Best, Jyotirmoy Deshmukh, 2019-10-30
5. [RBED: Reward Based Epsilon Decay](https://arxiv.org/abs/1910.13701) by Aakash Maroti, 2019-10-30