## IJCAI 2019
1. **A Dual Reinforcement Learning Framework for Unsupervised Text Style Transfer**: Fuli Luo, Peng Li, Jie Zhou, Pengcheng Yang, Baobao Chang, Xu Sun, Zhifang Sui
2. **A Restart-based Rank-1 Evolution Strategy for Reinforcement Learning**: Zefeng Chen, Yuren Zhou, Xiao-yu He, Siyu Jiang
3. **An Actor-Critic-Attention Mechanism for Deep Reinforcement Learning in Multi-view Environments**:Elaheh Barati, Xuewen Chen
4. **An Atari Model Zoo for Analyzing, Visualizing, and Comparing Deep Reinforcement Learning Agents**: Felipe Such, Vashisht Madhavan, Rosanne Liu, Rui Wang, Pablo Samuel Castro, Yulun Li, Jiale Zhi, Ludwig Schubert, Marc G. Bellemare, Jeff Clune, Joel Lehman
5. **Automatic Successive Reinforcement Learning with Multiple Auxiliary Rewards**: Zhao-Yang Fu, De-Chuan Zhan, Xin-Chun Li, Yi-Xing Lu
6. **Autoregressive Policies for Continuous Control Deep Reinforcement Learning**:Dmytro Korenkevych, Ashique Rupam Mahmood, Gautham Vasan, James Bergstra
7. **Deep Multi-Agent Reinforcement Learning with Discrete-Continuous Hybrid Action Spaces** :Haotian Fu, Hongyao Tang, Jianye Hao, Zihan Lei, Yingfeng Chen, Changjie Fan
8. **Dynamic Electronic Toll Collection via Multi-Agent Deep Reinforcement Learning with Edge-Based Graph Convolutional Network Representation**:Wei Qiu, Haipeng Chen, Bo An
9. **Energy-Efficient Slithering Gait Exploration for a Snake-Like Robot Based on Reinforcement Learning**: Zhenshan Bing, Christian Lemke, Zhuangyi Jiang, Kai Huang, Alois Knoll
10. **Explaining Reinforcement Learning to Mere Mortals**: An Empirical Study: Andrew Anderson, Jonathan Dodge, Amrita Sadarangani, Zoe Juozapaitis, Evan Newman, Jed Irvine, Souti Chattopadhyay, Alan Fern, Margaret Burnett
11. **Hybrid Actor-Critic Reinforcement Learning in Parameterized Action Space**: Zhou Fan, Rui Su, Weinan Zhang, Yong Yu
12. **Incremental Learning of Planning Actions in Model-Based Reinforcement Learning**: Alvin Ng, Ron Petrick
13. **Interactive Reinforcement Learning with Dynamic Reuse of Prior Knowledge from Human/Agent's Demonstration**: Zhaodong Wang, Matt Taylor
14. **Interactive Teaching Algorithms for Inverse Reinforcement Learning**: Parameswaran Kamalaruban, Rati Devidze, Volkan Cevher, Adish Singla
15. **Large-Scale Home Energy Management Using Entropy-Based Collective Multiagent Deep Reinforcement Learning**: Yaodong Yang, Jianye Hao, Yan Zheng, Chao Yu
16. **Meta Reinforcement Learning with Task Embedding and Shared Policy**: Lin Lan, Zhenguo Li, Xiaohong Guan, Pinghui Wang
17. **Metatrace Actor-Critic: Online Step-Size Tuning by Meta-gradient Descent for Reinforcement Learning Control**: Kenny Young, Baoxiang Wang, Matthew E. Taylor
18. **Playing Card-Based RTS Games with Deep Reinforcement Learning**: Tianyu Liu, Zijie Zheng, Hongchang Li, Kaigui Bian, Lingyang Song
19. **Playing FPS Games With Environment-Aware Hierarchical Reinforcement Learning**: Shihong Song, Jiayi Weng, Hang Su, Dong Yan, Haosheng Zou, Jun Zhu
20. **Reinforcement Learning Experience Reuse with Policy Residual Representation**: WenJi Zhou, Yang Yu, Yingfeng Chen, Kai Guan, Tangjie Lv, Changjie Fan, Zhi-Hua Zhou
21. **Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation**: Yang Gao, Christian Meyer, Mohsen Mesgar, Iryna Gurevych
22. **Sharing Experience in Multitask Reinforcement Learning**: Tung-Long Vuong, Do-Van Nguyen, Tai-Long Nguyen, Cong-Minh Bui, Hai-Dang Kieu, Viet-Cuong Ta, Quoc-Long Tran, Thanh-Ha Le
23. **SlateQ: A Tractable Decomposition for Reinforcement Learning with Recommendation Sets**: Eugene Ie, Vihan Jain, Jing Wang, Sanmit Narvekar, Ritesh Agarwal, Rui Wu, Heng-Tze Cheng, Tushar Chandra, Craig Boutilier
24. **Soft Policy Gradient Method for Maximum Entropy Deep Reinforcement Learning**: Wenjie Shi, Shiji Song, Cheng Wu
25. **Solving Continual Combinatorial Selection via Deep Reinforcement Learning**: HyungSeok Song, Hyeryung Jang, Hai H. Tran, Se-eun Yoon, Kyunghwan Son, Donggyu Yun, Hyoju Chung, Yung Yi
26. **Successor Options: An Option Discovery Framework for Reinforcement Learning**: Rahul Ramesh, Manan Tomar, Balaraman Ravindran
27. **Transfer of Temporal Logic Formulas in Reinforcement Learning**: Zhe Xu, Ufuk Topcu
28. **Using Natural Language for Reward Shaping in Reinforcement Learning**: Prasoon Goyal, Scott Niekum, Raymond Mooney
29. **Value Function Transfer for Deep Multi-Agent Reinforcement Learning Based on N-Step Returns**: Yong Liu, Yujing Hu, Yang Gao, Yingfeng Chen, Changjie Fan
30. **Failure-Scenario Maker for Rule-Based Agent using Multi-agent Adversarial Reinforcement Learning and its Application to Autonomous Driving**: Akifumi Wachi
31. **LTL and Beyond: Formal Languages for Reward Function Specification in Reinforcement Learning**: Alberto Camacho, Rodrigo Toro Icarte, Toryn Q. Klassen, Richard Valenzano, Sheila McIlraith
32. **A Survey of Reinforcement Learning Informed by Natural Language**: Jelena Luketina↵, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstett, Shimon Whiteson, Tim RocktÃ¤schel
33. **Leveraging Human Guidance for Deep Reinforcement Learning Tasks**: Ruohan Zhang, Faraz Torabi, Lin Guan, Dana H. Ballard, Peter Stone
34. **CRSRL: Customer Routing System using Reinforcement Learning**: Chong Long, Zining Liu, Xiaolu Lu, Zehong Hu, Yafang Wang
35. **Deep Reinforcement Learning for Ride-sharing Dispatching and Repositioning**: Zhiwei (Tony) Qin, Xiaocheng Tang, Yan Jiao, Fan Zhang, Chenxi Wang
36. **Learning Deep Decentralized Policy Network by Collective Rewards for Real-Time Combat Game**: Peixi Peng, Junliang Xing, Lili Cao, Lisen Mu, Chang Huang
37. **Monte Carlo Tree Search for Policy Optimization**: Xiaobai Ma, Katherine Driggs-Campbell, Zongzhang Zhang, Mykel J. Kochenderfer
38. **On Principled Entropy Exploration in Policy Optimization**: Jincheng Mei, Chenjun Xiao, Ruitong Huang, Dale Schuurmans, Martin Müller
39. **Recurrent Existence Determination Through Policy Optimization**: Baoxiang Wang
40. **Diversity-Inducing Policy Gradient: Using Maximum Mean Discrepancy to Find a Set of Diverse Policies**: Muhammad Masood, Finale Doshi-Velez
41. **A probabilistic logic for resource-bounded multi-agent systems**: Hoang Nga Nguyen, Abdur Rakib
42.  **A Value-based Trust Assessment Model for Multi-agent Systems**: Kinzang Chhogyal, Abhaya Nayak, Aditya Ghose, Hoa Khanh Dam
43. **Branch-and-Cut-and-Price for Multi-Agent Pathfinding**: Edward Lam, Pierre Le Bodic, Daniel Harabor, Peter J. Stuckey
44. **Decidability of Model Checking Multi-Agent Systems with Regular Expressions against Epistemic HS Specifications**: Jakub Michaliszyn, Piotr Witkowski
45. **Improved Heuristics for Multi-Agent Path Finding with Conflict-Based Search**: Jiaoyang Li, Eli Boyarski, Ariel Felner, Hang Ma, Sven Koenig
46. **Integrating Decision Sharing with Prediction in Decentralized Planning for Multi-Agent Coordination under Uncertainty**: Minglong Li, Wenjing Yang, Zhongxuan Cai, Shaowu Yang, Ji Wang
47. **Multi-agent Attentional Activity Recognition**: Kaixuan Chen, Lina Yao, Dalin Zhang, Bin Guo, Zhiwen Yu
48. **Multi-Agent Pathfinding with Continuous Time**: Anton Andreychuk, Konstantin Yakovlev, Dor Atzmon, Roni Stern
49. **Priority Inheritance with Backtracking for Iterative Multi-agent Path Finding**: Keisuke Okumura, Manao Machida, Xavier Défago, Yasumasa Tamura
50. **The Interplay of Emotions and Norms in Multiagent Systems**: Anup K. Kalia, Nirav Ajmeri, Kevin S. Chan, Jin-Hee Cho, Sibel Adali, Munindar Singh
51. **Unifying Search-based and Compilation-based Approaches to Multi-agent Path Finding through Satisfiability Modulo Theories**: Pavel Surynek
52. **Implicitly Coordinated Multi-Agent Path Finding under Destination Uncertainty: Success Guarantees and Computational Complexity (Extended Abstract)**: Bernhard Nebel, Thomas Bolander, Thorsten Engesser, Robert Mattmüller
53. **Embodied Conversational AI Agents in a Multi-modal Multi-agent Competitive Dialogue**: Rahul Divekar, Xiangyang Mou, Lisha Chen, Maíra Gatti de Bayser, Melina Alberio Guerra, Hui Su
54. **Multi-Agent Path Finding on Ozobots**: Roman Barták, Ivan Krasičenko, Jiří Švancara
55. **Multi-Agent Visualization for Explaining Federated Learning**: Xiguang Wei, Quan Li, Yang Liu, Han Yu, Tianjian Chen, Qiang Yang
56. **Automated Machine Learning with Monte-Carlo Tree Search**: Herilalaina Rakotoarison, Marc Schoenauer, Michele Sebag
57. **Influence of State-Variable Constraints on Partially Observable Monte Carlo Planning**: Alberto Castellini, Georgios Chalkiadakis, Alessandro Farinelli
58. **Multiple Policy Value Monte Carlo Tree Search**: Li-Cheng Lan, Wei Li, Ting han Wei, I-Chen Wu
59. **Subgoal-Based Temporal Abstraction in Monte-Carlo Tree Search**: Thomas Gabor, Jan Peter, Thomy Phan, Christian Meyer, Claudia Linnhoff-Popien
60. **A Convergence Analysis of Distributed SGD with Communication-Efficient Gradient Sparsification**: Shaohuai Shi, Kaiyong Zhao, Qiang Wang, Zhenheng Tang, Xiaowen Chu
61. **AsymDPOP: Complete Inference for Asymmetric Distributed Constraint Optimization Problems**: Yanchen Deng, Ziyu Chen, Dingding Chen, Wenxin Zhang, Xingqiong Jiang
62. **Distributed Collaborative Feature Selection Based on Intermediate Representation**: Xiucai Ye, Hongmin Li, Akira Imakura, Tetsuya Sakurai
63. **FABA: An Algorithm for Fast Aggregation against Byzantine Attacks in Distributed Neural Networks**: Qi Xia, Zeyi Tao, Zijiang Hao, Qun Li
64. **Faster Distributed Deep Net Training: Computation and Communication Decoupled Stochastic Gradient Descent**: Shuheng Shen, Linli Xu, Jingchang Liu, Xianfeng Liang, Yifei Cheng
65. **Fully Distributed Bayesian Optimization with Stochastic Policies**: Javier Garcia-Barcos, Ruben Martinez-Cantin