# Deep Reinforcement Learning(深度强化学习)

本仓库由“深度强化学习实验室(DeepRL-Lab)”创建，希望能够为所有DRL研究者，学习者和爱好者提供一个交流平台。

深度强化学习实验室成员来自于**学术界和工业界**，*包括清华、山大、浙大、北航、北理工、国防科大、帝国理工、CMU、南洋理工、柏林工业、西悉尼大学等高校，也包含腾讯、阿里巴巴、网易、头条等企业界的伙伴*。有本科、硕士和博士，也有博后和高校教师等，虽来自不同的高校和企业，但都有一颗相同的心—— “**成为DRL领域的大佬！**”，是梦想让大家汇聚于此！

因此DeepRL-Lab将自己的使命定位于“四个帮助”：
>
+ 【1】提供最全面的深度强化学习书籍、资料、综述等学习资源。
+ 【2】阐述深度强化学习的基本原理、前沿算法、场景应用、竞赛分析、论文分享等专业知识。
+ 【3】分享最前沿的业界动态和行业发展趋势。
+ 【4】汇聚所有深度强化学习领域的研究者与爱好者。

### 背景
如今机器学习发展如此迅猛，各类算法层出不群，特别是深度神经网络在计算机视觉、自然语言处理、时间序列预测等多个领域更是战果累累，可以说这波浪潮带动了很多人进入深度学习领域，也成就了其一番事业。而强化学习作为一门灵感来源于心理学中的行为主义理论的学科，其内容涉及概率论、统计学、逼近论、凸分析、计算复杂性理论、运筹学等多学科知识，难度之大，门槛之高，导致其发展速度特别缓慢。围棋作为人类的娱乐游戏中复杂度最高的一个，它横竖各有19条线，共有361个落子点，双方交替落子，状态空间高达10的171次方(注：宇宙中的原子总数是10的80次方，即使穷尽整个宇宙的物质也不能存下围棋的所有可能性）
### 1、什么是深度强化学习？

>
+ 2015年10月，由Google DeepMind公司开发的AlphaGo程序击败了人类高级选手樊麾，成为第一个无需让子即可在19路棋盘上击败围棋职业棋手的计算机围棋程序，并写进了历史，论文发表在国际顶级期刊《Science》上。
+ 2016年3月，透过自我对弈数以万计盘进行练习强化，AlphaGo在一场五番棋比赛中4:1击败顶尖职业棋手李世石。
+ Master(AlphaGo版本)于2016年12月开始出现于弈城围棋网和腾讯野狐围棋网，取得60连胜的成绩，以其空前的实力轰动了围棋界。
+ DeepMind 如约公布了他们最新版AlphaGo论文(Nature)，介绍了迄今最强最新的版本AlphaGo Zero，使用纯强化学习，将价值网络和策略网络整合为一个架构，3天训练后就以100比0击败了上一版本的AlphaGo。AlphaGo已经退休，但技术永存。DeepMind已经完成围棋上的概念证明，接下来就是用强化学习创造改变世界的价值。

围棋被攻克证明了强化学习发展的威力，作为AlphoGo的带头人，强化学习界的大神，David Sliver及其团队可以说盛名远扬，其以前沿的目光发表了人工智能的终极目标是：
